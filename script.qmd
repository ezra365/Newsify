---
title: "Newsify"
format: 
    pdf: 
        toc: false
        toc-depth: 2
        number-sections: true
        code-block-border-left: true
        colorlinks: true
author: "Ezra Sharpe"
execute:
    engine: python
---

### Part 1 - Setup 

```{python}

import os
import json

# Load API keys from a JSON file
def load_api_keys(filename):
    with open(filename, 'r') as file:
        keys = json.load(file)
    return keys

# Get the API key
api_keys = load_api_keys('key.json')
openai_api_key = api_keys.get('OPENAI_API_KEY')


def keys_available(api_key):
    # Checking it loaded succesfully
    return type(api_key)

# The API key should be a string, let's check without printing key
print(f"The API key type is: {keys_available(openai_api_key)}")

```

### Part 2 - Webscrape Articles

```{python}

url = "https://venturebeat.com/category/ai/"

class Date(Enum):
  today = 'today'
  yesterday = 'yesterday'
  more = 'more'

def __str__(self):
      return self.value

def get_text(detail_url):
    info = BeautifulSoup(requests.get(detail_url).text, 'html.parser')
    article_content = info.select_one('div.article-content')
    if article_content:
        return '\n'.join([p.text.strip() for p in article_content.findChildren('p', recursive=False)])
    else:
        return None  # Or any appropriate value or indication that no content was found


def scrape(date = Date.today):
  rr = requests.get( url )

  soup = BeautifulSoup(rr.text, "html.parser")


  articles= soup.find_all('article', class_='ArticleListing')

  print('#### input ###')
  print('date: ', date)
  print('#### === ### \n')
  data = []
  for article in articles:
    t.sleep(2)
    if not article.time:
      continue
    time = article.time.text.strip()
    item = {
        'title': article.h2.text.strip(),
        'url': article.a['href'],
        'time': time
    }
    time_obj = datetime.strptime(time, '%B %d, %Y %H:%M %p').date()
    if date == Date.today:
      if time_obj == datetime.today().date():
        item['text'] = get_text(article.a['href'])
        data.append(item)
    elif date == Date.yesterday:
      if time_obj == (datetime.today() - timedelta(days=1)).date():
        item['text'] = get_text(article.a['href'])
        data.append(item)
    elif date == Date.more:
      item['text'] = get_text(article.a['href'])
      data.append(item)

  return data
     

#@title Select days to pull news {run: "auto"}

period = 'yesterday' #@param ['today', 'yesterday', 'more']

def get_date(period):
  if period == 'today':
    return Date.today
  elif period == 'yesterday':
    return Date.yesterday
  else:
    return Date.more
     

#@title Scraper Results
date = get_date(period)
data = scrape(date)
print('total articles:', len(data))

```

### Part 3 - Generate Summaries

```{python}

from IPython.display import Markdown
from langchain_openai import ChatOpenAI
from langchain.schema import (
    HumanMessage
)

def get_template(title, text):

  # prepare template for prompt
  template = """You are an advanced ai assistant that summarizes online articles.

  Here's the article you need to summarize:
  ==========================
  Title: {article_title}

  Text: {article_text}
  ==========================

  Write a summary of the previous article in 200 words or less, with a particular focus on communicating the key messages.
  """

  prompt = template.format(article_title=title, article_text=text)

  messages = [HumanMessage(content=prompt)]
  return messages

def get_summary(messages, openai_api_key):
    # instantiate model with API key
    chat = ChatOpenAI(api_key=openai_api_key, temperature=0)

    # generate summary
    summary = chat(messages)
    return summary.content


def get_output(article):
  title = article['title']
  url = article['url']
  date = article['time']
  text = article['text']

  messages = get_template(title, text)
  summary = get_summary(messages, openai_api_key)
  output = f"**{title}** {summary} [View Full]({url})"
  return output

def summarize_articles(data):
  markdown_list = []
  for article in data:
    t.sleep(30) # can only process 3 requests per minute on free account
    output = get_output(article)
    markdown_list.append(output)

  markdown_string = ''.join(markdown_list)
  return markdown_string

    
#@title Article Summaries
summaries = summarize_articles(data)
Markdown(summaries)

```